import datetime
import pandas as pd

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.providers.postgres.operators.postgres import PostgresOperator

PLAYER_CSV = "/opt/airflow/dags/ingestion_zone/gta5_steam_player_data.csv"
VIEWER_CSV = "/opt/airflow/dags/ingestion_zone/gta5_twitch_viewer_data.csv"
COMBINED_CSV = "/opt/airflow/dags/ingestion_zone/gta5_player_and_viewer_data.csv"

POSTGRES_CONN_ID = "data_eng"


def merge_and_clean_datasets():
    df1 = pd.read_csv(PLAYER_CSV, delimiter=";")
    df2 = pd.read_csv(VIEWER_CSV, delimiter=";")

    # average players exist only for 2023 and later
    df1 = df1.drop(columns="Average Players")

    df_combined = pd.merge(df1, df2, on="DateTime")

    df_combined.rename(
        columns={
            "DateTime": "date",
            "Players": "players",
            "Viewers": "viewers",
        },
        inplace=True,
    )

    # fix merge type cast
    df_combined["players"] = df_combined["players"].astype(int)

    df_combined["game"] = "Grand Theft Auto 5"

    # cut "00:00:00" out of string
    df_combined["date"] = df_combined["date"].str[:10].astype(str)

    df_combined.to_csv(COMBINED_CSV, index=False)
    print(f"The files were successfully combined and saved: {COMBINED_CSV}")


def get_airflow_sql_connection():
    pg_hook = PostgresHook.get_hook(POSTGRES_CONN_ID)
    connection = pg_hook.get_conn()
    return connection


def move_to_postgres():
    conn = get_airflow_sql_connection()
    cur = conn.cursor()

    with open(COMBINED_CSV) as f:
        cur.copy_expert(
            "COPY staging_game_interest(date, players, viewers, game) FROM stdin WITH (FORMAT csv, HEADER, DELIMITER ',');",
            f,
        )

    conn.commit()
    cur.close()
    conn.close()


default_args_dict = {
    "start_date": datetime.datetime.now(datetime.timezone.utc),
    "concurrency": 1,
    "retries": 1,
    "retry_delay": datetime.timedelta(minutes=5),
}

dag = DAG(
    dag_id="wrangle_gta5_player_and_viewer_data",
    default_args=default_args_dict,
    schedule="@weekly",
    catchup=False,
)

task_merge_and_clean_datasets = PythonOperator(
    task_id="task_merge_and_clean_datasets",
    python_callable=merge_and_clean_datasets,
    dag=dag,
)

task_create_sql_table = PostgresOperator(
    task_id="task_create_sql_table",
    postgres_conn_id="data_eng",
    sql="CREATE TABLE IF NOT EXISTS staging_game_interest (id INTEGER PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY, date DATE, players INTEGER, viewers INTEGER, game TEXT);",
    dag=dag,
)

task_move_to_postgres = PythonOperator(
    task_id="task_move_to_postgres",
    python_callable=move_to_postgres,
    dag=dag,
)

task_merge_and_clean_datasets >> task_create_sql_table >> task_move_to_postgres
